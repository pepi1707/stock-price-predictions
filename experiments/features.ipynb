{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "restricted-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime\n",
    "import talib\n",
    "import talib.abstract as tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weekly-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "first_table = payload[0]\n",
    "tickets = first_table['Symbol'].values.tolist()\n",
    "tickets.remove('BRK.B')\n",
    "tickets.remove('BF.B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artificial-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks = []\n",
    "for ticket in tickets:\n",
    "    stocks = pd.read_csv('../datasets/yahoo/' + ticket + '.csv')\n",
    "    stocks.rename(columns=str.lower, inplace=True)\n",
    "    all_stocks.append(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "political-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df):\n",
    "    \n",
    "    # ROC 10\n",
    "    roc = tabs.ROC(df, timeperiod=10)\n",
    "    roc = np.nan_to_num(roc)\n",
    "    df['roc'] = roc\n",
    "    \n",
    "    # SMA 10\n",
    "    sma = tabs.SMA(df, timeperiod=10)\n",
    "    sma = np.nan_to_num(sma)\n",
    "    df['sma'] = sma\n",
    "    \n",
    "    # MACD, MACD SIGNAL and MACD HIST\n",
    "    \n",
    "    macd, macdsignal, macdhist = talib.MACD(df['close'])\n",
    "    macd = np.nan_to_num(macd)\n",
    "    macdsignal = np.nan_to_num(macdsignal)\n",
    "    macdhist = np.nan_to_num(macdhist)\n",
    "    df['macd'] = macd\n",
    "    df['macd_signal'] = macdsignal\n",
    "    df['macd_hist'] = macdhist\n",
    "    \n",
    "    # CCI 10\n",
    "    cci = tabs.CCI(df, timeperiod=10)\n",
    "    cci = np.nan_to_num(cci)\n",
    "    df['cci'] = cci\n",
    "    \n",
    "    #     MTM 10 \n",
    "    mtm = tabs.MOM(df, timeperiod=10)\n",
    "    mtm = np.nan_to_num(mtm)\n",
    "    df['mtm'] = mtm\n",
    "    \n",
    "    #     RSI 5 \n",
    "    rsi = tabs.RSI(df, timeperiod=5)\n",
    "    rsi = np.nan_to_num(rsi)\n",
    "    df['rsi'] = rsi\n",
    "    \n",
    "    #     WNR 9\n",
    "    wnr = tabs.WMA(df, timeperiod=9)\n",
    "    wnr = np.nan_to_num(wnr)\n",
    "    df['wnr'] = wnr\n",
    "    \n",
    "    #     SLOWK & SLOWD\n",
    "    slowk, slowd = talib.STOCH(df['high'], df['low'], df['close'])\n",
    "    slowk = np.nan_to_num(slowk)\n",
    "    slowd = np.nan_to_num(slowd)\n",
    "    df['slowk'] = slowk\n",
    "    df['slowd'] = slowd\n",
    "    \n",
    "    #     ADOSC \n",
    "    adosc = tabs.ADOSC(df)\n",
    "    adosc = np.nan_to_num(adosc)\n",
    "    df['adosc'] = adosc\n",
    "    \n",
    "    #     AARON\n",
    "    aroondown, aroonup = talib.AROON(df['high'], df['low'])\n",
    "    aroondown = np.nan_to_num(aroondown)\n",
    "    aroonup = np.nan_to_num(aroonup)\n",
    "    df['aroon_down'] = aroondown\n",
    "    df['aroon_up'] = aroonup\n",
    "    \n",
    "    #     BBANDS\n",
    "    upper, middle, lower = talib.BBANDS(df['close'], matype=0)\n",
    "    upper = np.nan_to_num(upper)\n",
    "    df['upper'] = upper\n",
    "    middle = np.nan_to_num(middle)\n",
    "    df['middle'] = middle\n",
    "    lower = np.nan_to_num(lower)\n",
    "    df['bbands'] = lower\n",
    "    \n",
    "    # SAR\n",
    "    sar = tabs.SAR(df)\n",
    "    sar = np.nan_to_num(sar)\n",
    "    df['sar'] = sar\n",
    "    \n",
    "    # BOP\n",
    "    bop = tabs.BOP(df)\n",
    "    bop = np.nan_to_num(bop)\n",
    "    df['bop'] = bop\n",
    "    \n",
    "    # DX\n",
    "    dx = tabs.DX(df)\n",
    "    dx = np.nan_to_num(dx)\n",
    "    df['dx'] = dx\n",
    "    \n",
    "    # PLUS_DI\n",
    "    plus_di = tabs.PLUS_DI(df)\n",
    "    plus_di = np.nan_to_num(plus_di)\n",
    "    df['plus_di'] = plus_di\n",
    "    \n",
    "    # WIILR\n",
    "    willr = tabs.WILLR(df)\n",
    "    willr = np.nan_to_num(willr)\n",
    "    df['willr'] = willr\n",
    "    \n",
    "    # TRIX\n",
    "    trix = tabs.TRIX(df)\n",
    "    trix = np.nan_to_num(trix)\n",
    "    df['trix'] = trix\n",
    "    \n",
    "    # OBV\n",
    "    obv = tabs.OBV(df)\n",
    "    obv = np.nan_to_num(obv)\n",
    "    df['obv'] = obv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "educated-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticket, stock in zip(tickets, all_stocks):\n",
    "    s = stock.copy()\n",
    "    feature_extraction(s)\n",
    "    s = s.iloc[10:]\n",
    "    s.to_csv('../datasets/enriched/' + ticket + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ordered-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks = []\n",
    "for ticket in tickets:\n",
    "    stocks = pd.read_csv('../datasets/enriched/' + ticket + '.csv')\n",
    "    stocks = stocks[stocks.columns[:-7]]\n",
    "    all_stocks.append(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "muslim-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "      <th>roc</th>\n",
       "      <th>sma</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi</th>\n",
       "      <th>wnr</th>\n",
       "      <th>slowk</th>\n",
       "      <th>slowd</th>\n",
       "      <th>adosc</th>\n",
       "      <th>aroon_down</th>\n",
       "      <th>aroon_up</th>\n",
       "      <th>upper</th>\n",
       "      <th>middle</th>\n",
       "      <th>bbands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206.789993</td>\n",
       "      <td>202.190002</td>\n",
       "      <td>202.869995</td>\n",
       "      <td>206.570007</td>\n",
       "      <td>2623000.0</td>\n",
       "      <td>191.088211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210.399994</td>\n",
       "      <td>206.589996</td>\n",
       "      <td>207.089996</td>\n",
       "      <td>209.720001</td>\n",
       "      <td>2967300.0</td>\n",
       "      <td>194.002090</td>\n",
       "      <td>1.524904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207.119995</td>\n",
       "      <td>204.050003</td>\n",
       "      <td>206.589996</td>\n",
       "      <td>204.929993</td>\n",
       "      <td>2229700.0</td>\n",
       "      <td>190.881744</td>\n",
       "      <td>-2.284002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208.970001</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>206.460007</td>\n",
       "      <td>208.860001</td>\n",
       "      <td>2000400.0</td>\n",
       "      <td>194.542313</td>\n",
       "      <td>1.917732</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209.149994</td>\n",
       "      <td>207.389999</td>\n",
       "      <td>207.910004</td>\n",
       "      <td>208.410004</td>\n",
       "      <td>1534400.0</td>\n",
       "      <td>194.123199</td>\n",
       "      <td>-0.215454</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.148209</td>\n",
       "      <td>207.698001</td>\n",
       "      <td>204.247793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>161.889999</td>\n",
       "      <td>158.500000</td>\n",
       "      <td>160.399994</td>\n",
       "      <td>160.020004</td>\n",
       "      <td>1625100.0</td>\n",
       "      <td>160.020004</td>\n",
       "      <td>0.464594</td>\n",
       "      <td>156.8270</td>\n",
       "      <td>-1.440415</td>\n",
       "      <td>-1.428655</td>\n",
       "      <td>...</td>\n",
       "      <td>62.246209</td>\n",
       "      <td>157.420890</td>\n",
       "      <td>74.490395</td>\n",
       "      <td>63.224442</td>\n",
       "      <td>-8.872658e+05</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>161.197062</td>\n",
       "      <td>157.810001</td>\n",
       "      <td>154.422939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>161.789993</td>\n",
       "      <td>159.009995</td>\n",
       "      <td>159.809998</td>\n",
       "      <td>159.830002</td>\n",
       "      <td>1852700.0</td>\n",
       "      <td>159.830002</td>\n",
       "      <td>-0.118737</td>\n",
       "      <td>156.8390</td>\n",
       "      <td>-1.227758</td>\n",
       "      <td>-1.388476</td>\n",
       "      <td>...</td>\n",
       "      <td>60.704453</td>\n",
       "      <td>158.085557</td>\n",
       "      <td>76.644004</td>\n",
       "      <td>70.838388</td>\n",
       "      <td>-9.460893e+05</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>161.991619</td>\n",
       "      <td>158.298001</td>\n",
       "      <td>154.604384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>162.729996</td>\n",
       "      <td>160.169998</td>\n",
       "      <td>161.250000</td>\n",
       "      <td>160.619995</td>\n",
       "      <td>1746000.0</td>\n",
       "      <td>160.619995</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>157.5860</td>\n",
       "      <td>-0.984136</td>\n",
       "      <td>-1.307608</td>\n",
       "      <td>...</td>\n",
       "      <td>65.186027</td>\n",
       "      <td>158.759778</td>\n",
       "      <td>73.449505</td>\n",
       "      <td>74.861301</td>\n",
       "      <td>-1.244383e+06</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>161.779680</td>\n",
       "      <td>159.376001</td>\n",
       "      <td>156.972322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>164.729996</td>\n",
       "      <td>160.399994</td>\n",
       "      <td>161.149994</td>\n",
       "      <td>164.440002</td>\n",
       "      <td>1860300.0</td>\n",
       "      <td>164.440002</td>\n",
       "      <td>2.378289</td>\n",
       "      <td>158.3770</td>\n",
       "      <td>-0.477318</td>\n",
       "      <td>-1.141550</td>\n",
       "      <td>...</td>\n",
       "      <td>79.392055</td>\n",
       "      <td>160.107112</td>\n",
       "      <td>80.620873</td>\n",
       "      <td>76.904794</td>\n",
       "      <td>-7.406573e+05</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.540377</td>\n",
       "      <td>160.838000</td>\n",
       "      <td>157.135624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>167.750000</td>\n",
       "      <td>163.660004</td>\n",
       "      <td>163.610001</td>\n",
       "      <td>166.604996</td>\n",
       "      <td>1174272.0</td>\n",
       "      <td>166.604996</td>\n",
       "      <td>1.316586</td>\n",
       "      <td>159.6125</td>\n",
       "      <td>0.097907</td>\n",
       "      <td>-0.893659</td>\n",
       "      <td>...</td>\n",
       "      <td>84.013476</td>\n",
       "      <td>161.661000</td>\n",
       "      <td>85.888248</td>\n",
       "      <td>79.986209</td>\n",
       "      <td>-3.028216e+05</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>167.760783</td>\n",
       "      <td>162.303000</td>\n",
       "      <td>156.845217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252902 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           high         low        open       close     volume   adj close  \\\n",
       "0    206.789993  202.190002  202.869995  206.570007  2623000.0  191.088211   \n",
       "1    210.399994  206.589996  207.089996  209.720001  2967300.0  194.002090   \n",
       "2    207.119995  204.050003  206.589996  204.929993  2229700.0  190.881744   \n",
       "3    208.970001  206.000000  206.460007  208.860001  2000400.0  194.542313   \n",
       "4    209.149994  207.389999  207.910004  208.410004  1534400.0  194.123199   \n",
       "..          ...         ...         ...         ...        ...         ...   \n",
       "501  161.889999  158.500000  160.399994  160.020004  1625100.0  160.020004   \n",
       "502  161.789993  159.009995  159.809998  159.830002  1852700.0  159.830002   \n",
       "503  162.729996  160.169998  161.250000  160.619995  1746000.0  160.619995   \n",
       "504  164.729996  160.399994  161.149994  164.440002  1860300.0  164.440002   \n",
       "505  167.750000  163.660004  163.610001  166.604996  1174272.0  166.604996   \n",
       "\n",
       "          roc       sma      macd  macd_signal  ...        rsi         wnr  \\\n",
       "0    0.000000    0.0000  0.000000     0.000000  ...   0.000000    0.000000   \n",
       "1    1.524904    0.0000  0.000000     0.000000  ...   0.000000    0.000000   \n",
       "2   -2.284002    0.0000  0.000000     0.000000  ...   0.000000    0.000000   \n",
       "3    1.917732    0.0000  0.000000     0.000000  ...   0.000000    0.000000   \n",
       "4   -0.215454    0.0000  0.000000     0.000000  ...   0.000000    0.000000   \n",
       "..        ...       ...       ...          ...  ...        ...         ...   \n",
       "501  0.464594  156.8270 -1.440415    -1.428655  ...  62.246209  157.420890   \n",
       "502 -0.118737  156.8390 -1.227758    -1.388476  ...  60.704453  158.085557   \n",
       "503  0.494271  157.5860 -0.984136    -1.307608  ...  65.186027  158.759778   \n",
       "504  2.378289  158.3770 -0.477318    -1.141550  ...  79.392055  160.107112   \n",
       "505  1.316586  159.6125  0.097907    -0.893659  ...  84.013476  161.661000   \n",
       "\n",
       "         slowk      slowd         adosc  aroon_down    aroon_up       upper  \\\n",
       "0     0.000000   0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "1     0.000000   0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "2     0.000000   0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "3     0.000000   0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "4     0.000000   0.000000  0.000000e+00    0.000000    0.000000  211.148209   \n",
       "..         ...        ...           ...         ...         ...         ...   \n",
       "501  74.490395  63.224442 -8.872658e+05   57.142857   14.285714  161.197062   \n",
       "502  76.644004  70.838388 -9.460893e+05   50.000000    7.142857  161.991619   \n",
       "503  73.449505  74.861301 -1.244383e+06   42.857143    0.000000  161.779680   \n",
       "504  80.620873  76.904794 -7.406573e+05   35.714286    0.000000  164.540377   \n",
       "505  85.888248  79.986209 -3.028216e+05   28.571429  100.000000  167.760783   \n",
       "\n",
       "         middle      bbands  \n",
       "0      0.000000    0.000000  \n",
       "1      0.000000    0.000000  \n",
       "2      0.000000    0.000000  \n",
       "3      0.000000    0.000000  \n",
       "4    207.698001  204.247793  \n",
       "..          ...         ...  \n",
       "501  157.810001  154.422939  \n",
       "502  158.298001  154.604384  \n",
       "503  159.376001  156.972322  \n",
       "504  160.838000  157.135624  \n",
       "505  162.303000  156.845217  \n",
       "\n",
       "[252902 rows x 23 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat(all_stocks, axis=0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "automatic-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "blond-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "novel-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = NUM_FEATURES)\n",
    "pca.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "apparent-promotion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65869866e-01, 1.83491944e-01, 1.46459219e-01, 5.93871958e-02,\n",
       "       2.88988466e-02, 8.79215094e-03, 2.95258946e-03, 1.55300439e-03,\n",
       "       1.14434016e-03, 5.73754605e-04, 4.82080705e-04, 2.11204435e-04,\n",
       "       1.14396612e-04, 3.94793508e-05, 1.33801178e-05, 9.03816269e-06,\n",
       "       4.79224965e-06, 1.61874399e-06, 5.57469089e-07, 3.85740536e-07])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "geographic-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(X, timerange=10, split=0.1):\n",
    "    \n",
    "    train_size = int(X.shape[0] * (1 - split))\n",
    "    train_size = min(train_size, X.shape[0] - timerange)\n",
    "    \n",
    "    test_size = X.shape[0] - train_size - timerange\n",
    "    \n",
    "    X_train = np.ndarray(shape=(train_size, timerange, X.shape[1]))\n",
    "    for i in range(train_size):\n",
    "        X_train[i] = X[i:i+timerange]\n",
    "    \n",
    "    X_test = np.ndarray(shape=(test_size, timerange, X.shape[1]))\n",
    "    for i in range(test_size):\n",
    "        X_test[i] = X[train_size+i:train_size+i+timerange]\n",
    "        \n",
    "    return X_train, X_test\n",
    "    \n",
    "def prepare_output_data(X, timerange=10, split=0.1):\n",
    "    \n",
    "    train_size = int(X.shape[0] * (1 - split))\n",
    "    train_size = min(train_size, X.shape[0] - timerange)\n",
    "    \n",
    "    test_size = X.shape[0] - train_size - timerange\n",
    "    \n",
    "    Y_train = np.ndarray(shape=(train_size))\n",
    "    for i in range(train_size):\n",
    "        Y_train[i] = 1 if X[i+timerange-1] < X[i+timerange] else 0\n",
    "    \n",
    "    Y_test = np.ndarray(shape=(test_size))\n",
    "    for i in range(test_size):\n",
    "        Y_test[i] = 1 if X[train_size+i+timerange-1] < X[train_size+i+timerange] else 0\n",
    "    \n",
    "    return Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "liked-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMERANGE = 10\n",
    "\n",
    "X_train, X_test = [np.ndarray(shape=(0, TIMERANGE, NUM_FEATURES)) for i in range(2)]\n",
    "Y_train, Y_test = [np.ndarray(shape=(0)) for i in range(2)]\n",
    "for stock in all_stocks:\n",
    "    X = scaler.transform(stock)\n",
    "    X = pca.transform(X)\n",
    "    x_train, x_test = prepare_input_data(X, timerange=TIMERANGE)\n",
    "    y_train, y_test = prepare_output_data(stock['close'], timerange=TIMERANGE)\n",
    "    X_train = np.append(X_train, x_train, axis=0)\n",
    "    Y_train = np.append(Y_train, y_train, axis=0)\n",
    "    X_test = np.append(X_test, x_test, axis=0)\n",
    "    Y_test = np.append(Y_test, y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "wireless-welding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227410, 10, 20), (20462, 10, 20), (227410,), (20462,))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bulgarian-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# create and compile the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "social-prairie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "800/800 [==============================] - 37s 46ms/step - loss: 0.2690 - accuracy: 0.5064 - val_loss: 0.2493 - val_accuracy: 0.5216\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 35s 43ms/step - loss: 0.2512 - accuracy: 0.5135 - val_loss: 0.2493 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 42s 52ms/step - loss: 0.2510 - accuracy: 0.5135 - val_loss: 0.2491 - val_accuracy: 0.5270\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 37s 46ms/step - loss: 0.2506 - accuracy: 0.5159 - val_loss: 0.2498 - val_accuracy: 0.5034\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 34s 42ms/step - loss: 0.2506 - accuracy: 0.5161 - val_loss: 0.2490 - val_accuracy: 0.5286\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 46s 57ms/step - loss: 0.2504 - accuracy: 0.5184 - val_loss: 0.2489 - val_accuracy: 0.5286\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2500 - accuracy: 0.5198 - val_loss: 0.2491 - val_accuracy: 0.5279\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2500 - accuracy: 0.5200 - val_loss: 0.2489 - val_accuracy: 0.5290\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.2498 - accuracy: 0.5211 - val_loss: 0.2493 - val_accuracy: 0.5275\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.2499 - accuracy: 0.5193 - val_loss: 0.2487 - val_accuracy: 0.5290\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2498 - accuracy: 0.5205 - val_loss: 0.2490 - val_accuracy: 0.5286\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.2497 - accuracy: 0.5201 - val_loss: 0.2486 - val_accuracy: 0.5311\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 36s 45ms/step - loss: 0.2495 - accuracy: 0.5218 - val_loss: 0.2486 - val_accuracy: 0.5345\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 47s 58ms/step - loss: 0.2496 - accuracy: 0.5216 - val_loss: 0.2485 - val_accuracy: 0.5289\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 34s 42ms/step - loss: 0.2492 - accuracy: 0.5232 - val_loss: 0.2485 - val_accuracy: 0.5316\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 31s 38ms/step - loss: 0.2493 - accuracy: 0.5233 - val_loss: 0.2484 - val_accuracy: 0.5367\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 33s 41ms/step - loss: 0.2492 - accuracy: 0.5239 - val_loss: 0.2483 - val_accuracy: 0.5308\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.2490 - accuracy: 0.5246 - val_loss: 0.2483 - val_accuracy: 0.5336\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2489 - accuracy: 0.5256 - val_loss: 0.2482 - val_accuracy: 0.5312\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 32s 41ms/step - loss: 0.2490 - accuracy: 0.5247 - val_loss: 0.2486 - val_accuracy: 0.5255\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 37s 46ms/step - loss: 0.2488 - accuracy: 0.5269 - val_loss: 0.2482 - val_accuracy: 0.5339\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 29s 37ms/step - loss: 0.2487 - accuracy: 0.5253 - val_loss: 0.2481 - val_accuracy: 0.5328\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 39s 49ms/step - loss: 0.2487 - accuracy: 0.5269 - val_loss: 0.2481 - val_accuracy: 0.5325\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 38s 48ms/step - loss: 0.2488 - accuracy: 0.5254 - val_loss: 0.2481 - val_accuracy: 0.5351\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 44s 55ms/step - loss: 0.2486 - accuracy: 0.5268 - val_loss: 0.2483 - val_accuracy: 0.5331\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 31s 38ms/step - loss: 0.2486 - accuracy: 0.5261 - val_loss: 0.2482 - val_accuracy: 0.5317\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.2485 - accuracy: 0.5280 - val_loss: 0.2482 - val_accuracy: 0.5346\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2484 - accuracy: 0.5290 - val_loss: 0.2479 - val_accuracy: 0.5339\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2482 - accuracy: 0.5294 - val_loss: 0.2479 - val_accuracy: 0.5361\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 34s 42ms/step - loss: 0.2483 - accuracy: 0.5304 - val_loss: 0.2480 - val_accuracy: 0.5356\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 34s 43ms/step - loss: 0.2484 - accuracy: 0.5284 - val_loss: 0.2478 - val_accuracy: 0.5339\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2482 - accuracy: 0.5295 - val_loss: 0.2478 - val_accuracy: 0.5376\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 30s 37ms/step - loss: 0.2482 - accuracy: 0.5288 - val_loss: 0.2478 - val_accuracy: 0.5351\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2481 - accuracy: 0.5304 - val_loss: 0.2481 - val_accuracy: 0.5326\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 32s 39ms/step - loss: 0.2480 - accuracy: 0.5317 - val_loss: 0.2477 - val_accuracy: 0.5390\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2481 - accuracy: 0.5303 - val_loss: 0.2475 - val_accuracy: 0.5383\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.2480 - accuracy: 0.5316 - val_loss: 0.2478 - val_accuracy: 0.5345\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2480 - accuracy: 0.5318 - val_loss: 0.2475 - val_accuracy: 0.5360\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 37s 47ms/step - loss: 0.2479 - accuracy: 0.5333 - val_loss: 0.2476 - val_accuracy: 0.5352\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 34s 42ms/step - loss: 0.2479 - accuracy: 0.5331 - val_loss: 0.2476 - val_accuracy: 0.5400\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2477 - accuracy: 0.5347 - val_loss: 0.2475 - val_accuracy: 0.5358\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 31s 38ms/step - loss: 0.2478 - accuracy: 0.5339 - val_loss: 0.2476 - val_accuracy: 0.5364\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 40s 50ms/step - loss: 0.2477 - accuracy: 0.5335 - val_loss: 0.2475 - val_accuracy: 0.5369\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 34s 42ms/step - loss: 0.2476 - accuracy: 0.5354 - val_loss: 0.2473 - val_accuracy: 0.5387\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 37s 46ms/step - loss: 0.2475 - accuracy: 0.5357 - val_loss: 0.2472 - val_accuracy: 0.5401\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 35s 44ms/step - loss: 0.2475 - accuracy: 0.5363 - val_loss: 0.2473 - val_accuracy: 0.5419\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2475 - accuracy: 0.5353 - val_loss: 0.2473 - val_accuracy: 0.5390\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 42s 52ms/step - loss: 0.2473 - accuracy: 0.5359 - val_loss: 0.2476 - val_accuracy: 0.5380\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.2474 - accuracy: 0.5374 - val_loss: 0.2471 - val_accuracy: 0.5421\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 41s 51ms/step - loss: 0.2473 - accuracy: 0.5374 - val_loss: 0.2471 - val_accuracy: 0.5405\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_split=0.1, epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "threatened-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 2s 3ms/step - loss: 0.2491 - accuracy: 0.5210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24910366535186768, 0.5209656953811646]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "economic-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2575 - accuracy: 0.5166 - val_loss: 0.2501 - val_accuracy: 0.5025\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 4s 4ms/step - loss: 0.2501 - accuracy: 0.5206 - val_loss: 0.2486 - val_accuracy: 0.5337\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2494 - accuracy: 0.5254 - val_loss: 0.2488 - val_accuracy: 0.5316\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2489 - accuracy: 0.5297 - val_loss: 0.2480 - val_accuracy: 0.5403\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2484 - accuracy: 0.5344 - val_loss: 0.2475 - val_accuracy: 0.5368\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2481 - accuracy: 0.5352 - val_loss: 0.2475 - val_accuracy: 0.5359\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2480 - accuracy: 0.5353 - val_loss: 0.2473 - val_accuracy: 0.5385\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2478 - accuracy: 0.5373 - val_loss: 0.2475 - val_accuracy: 0.5362\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2476 - accuracy: 0.5365 - val_loss: 0.2473 - val_accuracy: 0.5360\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2474 - accuracy: 0.5395 - val_loss: 0.2471 - val_accuracy: 0.5380\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2473 - accuracy: 0.5401 - val_loss: 0.2471 - val_accuracy: 0.5351\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2471 - accuracy: 0.5406 - val_loss: 0.2471 - val_accuracy: 0.5391\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2470 - accuracy: 0.5406 - val_loss: 0.2469 - val_accuracy: 0.5412\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2469 - accuracy: 0.5411 - val_loss: 0.2465 - val_accuracy: 0.5425\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: 0.2467 - accuracy: 0.5428 - val_loss: 0.2465 - val_accuracy: 0.5410\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: 0.2466 - accuracy: 0.5425 - val_loss: 0.2463 - val_accuracy: 0.5419\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2465 - accuracy: 0.5434 - val_loss: 0.2461 - val_accuracy: 0.5426\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2463 - accuracy: 0.5437 - val_loss: 0.2460 - val_accuracy: 0.5415\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2462 - accuracy: 0.5449 - val_loss: 0.2461 - val_accuracy: 0.5434\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2461 - accuracy: 0.5448 - val_loss: 0.2458 - val_accuracy: 0.5451\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2460 - accuracy: 0.5452 - val_loss: 0.2456 - val_accuracy: 0.5461\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2459 - accuracy: 0.5458 - val_loss: 0.2456 - val_accuracy: 0.5472\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2458 - accuracy: 0.5453 - val_loss: 0.2452 - val_accuracy: 0.5472\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2457 - accuracy: 0.5460 - val_loss: 0.2454 - val_accuracy: 0.5441\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2456 - accuracy: 0.5462 - val_loss: 0.2451 - val_accuracy: 0.5473\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2456 - accuracy: 0.5473 - val_loss: 0.2451 - val_accuracy: 0.5475\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2454 - accuracy: 0.5474 - val_loss: 0.2454 - val_accuracy: 0.5461\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2453 - accuracy: 0.5477 - val_loss: 0.2449 - val_accuracy: 0.5476\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2453 - accuracy: 0.5476 - val_loss: 0.2448 - val_accuracy: 0.5500\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2452 - accuracy: 0.5477 - val_loss: 0.2447 - val_accuracy: 0.5501\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2451 - accuracy: 0.5483 - val_loss: 0.2445 - val_accuracy: 0.5503\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2450 - accuracy: 0.5487 - val_loss: 0.2446 - val_accuracy: 0.5496\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2450 - accuracy: 0.5501 - val_loss: 0.2445 - val_accuracy: 0.5507\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2449 - accuracy: 0.5502 - val_loss: 0.2444 - val_accuracy: 0.5486\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2448 - accuracy: 0.5511 - val_loss: 0.2443 - val_accuracy: 0.5524\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2448 - accuracy: 0.5496 - val_loss: 0.2442 - val_accuracy: 0.5493\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2447 - accuracy: 0.5511 - val_loss: 0.2444 - val_accuracy: 0.5521\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: 0.2446 - accuracy: 0.5507 - val_loss: 0.2439 - val_accuracy: 0.5518\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2446 - accuracy: 0.5513 - val_loss: 0.2441 - val_accuracy: 0.5525\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2445 - accuracy: 0.5516 - val_loss: 0.2438 - val_accuracy: 0.5543\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2444 - accuracy: 0.5526 - val_loss: 0.2437 - val_accuracy: 0.5552\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2443 - accuracy: 0.5518 - val_loss: 0.2436 - val_accuracy: 0.5534\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2442 - accuracy: 0.5537 - val_loss: 0.2434 - val_accuracy: 0.5545\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2442 - accuracy: 0.5531 - val_loss: 0.2437 - val_accuracy: 0.5544\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2441 - accuracy: 0.5532 - val_loss: 0.2434 - val_accuracy: 0.5558\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2439 - accuracy: 0.5538 - val_loss: 0.2436 - val_accuracy: 0.5539\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2438 - accuracy: 0.5552 - val_loss: 0.2432 - val_accuracy: 0.5557\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2437 - accuracy: 0.5542 - val_loss: 0.2431 - val_accuracy: 0.5573\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2438 - accuracy: 0.5537 - val_loss: 0.2434 - val_accuracy: 0.5552\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2436 - accuracy: 0.5556 - val_loss: 0.2431 - val_accuracy: 0.5574\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-2/assets\n",
      "766/766 [==============================] - 1s 937us/step - loss: 0.2501 - accuracy: 0.5175\n",
      "model evaluation:  [0.2500949203968048, 0.5174596905708313]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2563 - accuracy: 0.5170 - val_loss: 0.2486 - val_accuracy: 0.5291\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2500 - accuracy: 0.5216 - val_loss: 0.2487 - val_accuracy: 0.5256\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2496 - accuracy: 0.5243 - val_loss: 0.2492 - val_accuracy: 0.5299\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2493 - accuracy: 0.5270 - val_loss: 0.2484 - val_accuracy: 0.5326\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2490 - accuracy: 0.5291 - val_loss: 0.2484 - val_accuracy: 0.5314\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2484 - accuracy: 0.5332 - val_loss: 0.2472 - val_accuracy: 0.5383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2477 - accuracy: 0.5391 - val_loss: 0.2468 - val_accuracy: 0.5431\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2474 - accuracy: 0.5398 - val_loss: 0.2466 - val_accuracy: 0.5448\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2471 - accuracy: 0.5419 - val_loss: 0.2465 - val_accuracy: 0.5456\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2469 - accuracy: 0.5422 - val_loss: 0.2463 - val_accuracy: 0.5448\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 8s 9ms/step - loss: 0.2466 - accuracy: 0.5437 - val_loss: 0.2462 - val_accuracy: 0.5473\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2464 - accuracy: 0.5443 - val_loss: 0.2459 - val_accuracy: 0.5460\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2460 - accuracy: 0.5456 - val_loss: 0.2454 - val_accuracy: 0.5476\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2457 - accuracy: 0.5472 - val_loss: 0.2450 - val_accuracy: 0.5497\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2455 - accuracy: 0.5476 - val_loss: 0.2448 - val_accuracy: 0.5493\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2453 - accuracy: 0.5495 - val_loss: 0.2447 - val_accuracy: 0.5507\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2450 - accuracy: 0.5508 - val_loss: 0.2442 - val_accuracy: 0.5539\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2447 - accuracy: 0.5510 - val_loss: 0.2440 - val_accuracy: 0.5542\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2445 - accuracy: 0.5535 - val_loss: 0.2438 - val_accuracy: 0.5578\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2443 - accuracy: 0.5537 - val_loss: 0.2436 - val_accuracy: 0.5534\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.2440 - accuracy: 0.5541 - val_loss: 0.2433 - val_accuracy: 0.5583\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2439 - accuracy: 0.5554 - val_loss: 0.2429 - val_accuracy: 0.5575\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2436 - accuracy: 0.5556 - val_loss: 0.2425 - val_accuracy: 0.5588\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2435 - accuracy: 0.5564 - val_loss: 0.2427 - val_accuracy: 0.5581\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2432 - accuracy: 0.5562 - val_loss: 0.2423 - val_accuracy: 0.5573\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2430 - accuracy: 0.5577 - val_loss: 0.2422 - val_accuracy: 0.5576\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2427 - accuracy: 0.5589 - val_loss: 0.2418 - val_accuracy: 0.5613\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2424 - accuracy: 0.5609 - val_loss: 0.2416 - val_accuracy: 0.5589\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2422 - accuracy: 0.5607 - val_loss: 0.2418 - val_accuracy: 0.5614\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2421 - accuracy: 0.5607 - val_loss: 0.2414 - val_accuracy: 0.5598\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2418 - accuracy: 0.5620 - val_loss: 0.2414 - val_accuracy: 0.5587\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.2416 - accuracy: 0.5630 - val_loss: 0.2408 - val_accuracy: 0.5609\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2414 - accuracy: 0.5640 - val_loss: 0.2406 - val_accuracy: 0.5645\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2411 - accuracy: 0.5638 - val_loss: 0.2404 - val_accuracy: 0.5630\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2410 - accuracy: 0.5658 - val_loss: 0.2402 - val_accuracy: 0.5641\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2407 - accuracy: 0.5655 - val_loss: 0.2402 - val_accuracy: 0.5654\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2406 - accuracy: 0.5662 - val_loss: 0.2398 - val_accuracy: 0.5656\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2403 - accuracy: 0.5661 - val_loss: 0.2399 - val_accuracy: 0.5655\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2401 - accuracy: 0.5681 - val_loss: 0.2395 - val_accuracy: 0.5685\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2399 - accuracy: 0.5685 - val_loss: 0.2395 - val_accuracy: 0.5695\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2397 - accuracy: 0.5690 - val_loss: 0.2391 - val_accuracy: 0.5659\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2395 - accuracy: 0.5692 - val_loss: 0.2390 - val_accuracy: 0.5696\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2393 - accuracy: 0.5699 - val_loss: 0.2389 - val_accuracy: 0.5699\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2391 - accuracy: 0.5708 - val_loss: 0.2389 - val_accuracy: 0.5700\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2390 - accuracy: 0.5711 - val_loss: 0.2383 - val_accuracy: 0.5715\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2387 - accuracy: 0.5730 - val_loss: 0.2382 - val_accuracy: 0.5753\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2385 - accuracy: 0.5741 - val_loss: 0.2378 - val_accuracy: 0.5747\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2384 - accuracy: 0.5741 - val_loss: 0.2383 - val_accuracy: 0.5708\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.2382 - accuracy: 0.5737 - val_loss: 0.2376 - val_accuracy: 0.5758\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2380 - accuracy: 0.5750 - val_loss: 0.2375 - val_accuracy: 0.5748\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-3/assets\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516 - accuracy: 0.5164\n",
      "model evaluation:  [0.25159186124801636, 0.5163872838020325]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2557 - accuracy: 0.5161 - val_loss: 0.2494 - val_accuracy: 0.5162\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2500 - accuracy: 0.5203 - val_loss: 0.2483 - val_accuracy: 0.5349\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2495 - accuracy: 0.5262 - val_loss: 0.2487 - val_accuracy: 0.5281\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2490 - accuracy: 0.5303 - val_loss: 0.2482 - val_accuracy: 0.5359\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2487 - accuracy: 0.5330 - val_loss: 0.2477 - val_accuracy: 0.5360\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2483 - accuracy: 0.5350 - val_loss: 0.2474 - val_accuracy: 0.5424\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2477 - accuracy: 0.5395 - val_loss: 0.2469 - val_accuracy: 0.5466\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2472 - accuracy: 0.5426 - val_loss: 0.2465 - val_accuracy: 0.5453\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.2467 - accuracy: 0.5454 - val_loss: 0.2459 - val_accuracy: 0.5485\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2464 - accuracy: 0.5476 - val_loss: 0.2456 - val_accuracy: 0.5505\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.2458 - accuracy: 0.5491 - val_loss: 0.2457 - val_accuracy: 0.5530\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2453 - accuracy: 0.5505 - val_loss: 0.2445 - val_accuracy: 0.5536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2447 - accuracy: 0.5513 - val_loss: 0.2442 - val_accuracy: 0.5551\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2443 - accuracy: 0.5534 - val_loss: 0.2437 - val_accuracy: 0.5550\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2438 - accuracy: 0.5543 - val_loss: 0.2432 - val_accuracy: 0.5563\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2434 - accuracy: 0.5558 - val_loss: 0.2429 - val_accuracy: 0.5569\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2431 - accuracy: 0.5568 - val_loss: 0.2426 - val_accuracy: 0.5590\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2427 - accuracy: 0.5579 - val_loss: 0.2423 - val_accuracy: 0.5613\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2425 - accuracy: 0.5594 - val_loss: 0.2420 - val_accuracy: 0.5602\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2422 - accuracy: 0.5600 - val_loss: 0.2416 - val_accuracy: 0.5635\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2419 - accuracy: 0.5611 - val_loss: 0.2411 - val_accuracy: 0.5637\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2416 - accuracy: 0.5616 - val_loss: 0.2408 - val_accuracy: 0.5642\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2413 - accuracy: 0.5628 - val_loss: 0.2407 - val_accuracy: 0.5635\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2411 - accuracy: 0.5629 - val_loss: 0.2404 - val_accuracy: 0.5631\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2407 - accuracy: 0.5639 - val_loss: 0.2400 - val_accuracy: 0.5662\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2404 - accuracy: 0.5647 - val_loss: 0.2393 - val_accuracy: 0.5667\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2402 - accuracy: 0.5664 - val_loss: 0.2394 - val_accuracy: 0.5688\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2399 - accuracy: 0.5670 - val_loss: 0.2391 - val_accuracy: 0.5662\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2397 - accuracy: 0.5673 - val_loss: 0.2393 - val_accuracy: 0.5683\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2394 - accuracy: 0.5682 - val_loss: 0.2389 - val_accuracy: 0.5662\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2390 - accuracy: 0.5695 - val_loss: 0.2387 - val_accuracy: 0.5709\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2388 - accuracy: 0.5699 - val_loss: 0.2385 - val_accuracy: 0.5682\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2384 - accuracy: 0.5712 - val_loss: 0.2381 - val_accuracy: 0.5690\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2383 - accuracy: 0.5710 - val_loss: 0.2379 - val_accuracy: 0.5733\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2381 - accuracy: 0.5719 - val_loss: 0.2372 - val_accuracy: 0.5714\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2379 - accuracy: 0.5724 - val_loss: 0.2374 - val_accuracy: 0.5723\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2377 - accuracy: 0.5742 - val_loss: 0.2372 - val_accuracy: 0.5718\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2373 - accuracy: 0.5741 - val_loss: 0.2369 - val_accuracy: 0.5723\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2372 - accuracy: 0.5745 - val_loss: 0.2366 - val_accuracy: 0.5748\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2369 - accuracy: 0.5750 - val_loss: 0.2362 - val_accuracy: 0.5751\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2367 - accuracy: 0.5767 - val_loss: 0.2360 - val_accuracy: 0.5743\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2364 - accuracy: 0.5764 - val_loss: 0.2360 - val_accuracy: 0.5733\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2364 - accuracy: 0.5759 - val_loss: 0.2357 - val_accuracy: 0.5769\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2361 - accuracy: 0.5770 - val_loss: 0.2354 - val_accuracy: 0.5772\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2357 - accuracy: 0.5785 - val_loss: 0.2354 - val_accuracy: 0.5754\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2357 - accuracy: 0.5785 - val_loss: 0.2353 - val_accuracy: 0.5774\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2354 - accuracy: 0.5791 - val_loss: 0.2352 - val_accuracy: 0.5788\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2352 - accuracy: 0.5806 - val_loss: 0.2350 - val_accuracy: 0.5777\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2350 - accuracy: 0.5816 - val_loss: 0.2347 - val_accuracy: 0.5794\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2346 - accuracy: 0.5816 - val_loss: 0.2348 - val_accuracy: 0.5782\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-4/assets\n",
      "734/734 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.5179\n",
      "model evaluation:  [0.2511199712753296, 0.5178670287132263]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.2549 - accuracy: 0.5144 - val_loss: 0.2491 - val_accuracy: 0.5238\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2502 - accuracy: 0.5193 - val_loss: 0.2494 - val_accuracy: 0.5280\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2497 - accuracy: 0.5228 - val_loss: 0.2503 - val_accuracy: 0.5040\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2493 - accuracy: 0.5257 - val_loss: 0.2483 - val_accuracy: 0.5314\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2489 - accuracy: 0.5295 - val_loss: 0.2476 - val_accuracy: 0.5372\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.2482 - accuracy: 0.5345 - val_loss: 0.2473 - val_accuracy: 0.5398\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2475 - accuracy: 0.5389 - val_loss: 0.2470 - val_accuracy: 0.5436\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2471 - accuracy: 0.5417 - val_loss: 0.2468 - val_accuracy: 0.5426\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2467 - accuracy: 0.5438 - val_loss: 0.2463 - val_accuracy: 0.5455\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.2462 - accuracy: 0.5459 - val_loss: 0.2456 - val_accuracy: 0.5506\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2455 - accuracy: 0.5488 - val_loss: 0.2452 - val_accuracy: 0.5520\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2449 - accuracy: 0.5516 - val_loss: 0.2445 - val_accuracy: 0.5539\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2442 - accuracy: 0.5542 - val_loss: 0.2440 - val_accuracy: 0.5552\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2438 - accuracy: 0.5559 - val_loss: 0.2434 - val_accuracy: 0.5580\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2431 - accuracy: 0.5579 - val_loss: 0.2427 - val_accuracy: 0.5599\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2425 - accuracy: 0.5605 - val_loss: 0.2420 - val_accuracy: 0.5591\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2419 - accuracy: 0.5613 - val_loss: 0.2414 - val_accuracy: 0.5619\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2414 - accuracy: 0.5629 - val_loss: 0.2405 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2409 - accuracy: 0.5631 - val_loss: 0.2403 - val_accuracy: 0.5610\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2403 - accuracy: 0.5655 - val_loss: 0.2394 - val_accuracy: 0.5645\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2400 - accuracy: 0.5658 - val_loss: 0.2389 - val_accuracy: 0.5687\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2393 - accuracy: 0.5679 - val_loss: 0.2388 - val_accuracy: 0.5686\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2391 - accuracy: 0.5691 - val_loss: 0.2384 - val_accuracy: 0.5697\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2385 - accuracy: 0.5711 - val_loss: 0.2376 - val_accuracy: 0.5697\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.2381 - accuracy: 0.5723 - val_loss: 0.2373 - val_accuracy: 0.5717\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2377 - accuracy: 0.5722 - val_loss: 0.2370 - val_accuracy: 0.5737\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.2373 - accuracy: 0.5736 - val_loss: 0.2368 - val_accuracy: 0.5740\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2369 - accuracy: 0.5746 - val_loss: 0.2361 - val_accuracy: 0.5737\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2365 - accuracy: 0.5772 - val_loss: 0.2358 - val_accuracy: 0.5760\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2362 - accuracy: 0.5780 - val_loss: 0.2355 - val_accuracy: 0.5768\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2358 - accuracy: 0.5797 - val_loss: 0.2352 - val_accuracy: 0.5777\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2353 - accuracy: 0.5797 - val_loss: 0.2348 - val_accuracy: 0.5794\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2350 - accuracy: 0.5806 - val_loss: 0.2349 - val_accuracy: 0.5791\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2347 - accuracy: 0.5817 - val_loss: 0.2340 - val_accuracy: 0.5805\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2344 - accuracy: 0.5827 - val_loss: 0.2342 - val_accuracy: 0.5790\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2340 - accuracy: 0.5841 - val_loss: 0.2336 - val_accuracy: 0.5812\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.2337 - accuracy: 0.5856 - val_loss: 0.2336 - val_accuracy: 0.5842\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.2333 - accuracy: 0.5859 - val_loss: 0.2332 - val_accuracy: 0.5843\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.2332 - accuracy: 0.5864 - val_loss: 0.2330 - val_accuracy: 0.5870\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2327 - accuracy: 0.5880 - val_loss: 0.2327 - val_accuracy: 0.5855\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2326 - accuracy: 0.5885 - val_loss: 0.2331 - val_accuracy: 0.5853\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2322 - accuracy: 0.5902 - val_loss: 0.2328 - val_accuracy: 0.5853\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2319 - accuracy: 0.5903 - val_loss: 0.2323 - val_accuracy: 0.5866\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2317 - accuracy: 0.5903 - val_loss: 0.2319 - val_accuracy: 0.5860\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2312 - accuracy: 0.5916 - val_loss: 0.2322 - val_accuracy: 0.5858\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2311 - accuracy: 0.5923 - val_loss: 0.2319 - val_accuracy: 0.5863\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2308 - accuracy: 0.5940 - val_loss: 0.2313 - val_accuracy: 0.5874\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2304 - accuracy: 0.5950 - val_loss: 0.2311 - val_accuracy: 0.5889\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2302 - accuracy: 0.5955 - val_loss: 0.2314 - val_accuracy: 0.5890\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2300 - accuracy: 0.5966 - val_loss: 0.2311 - val_accuracy: 0.5901\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-5/assets\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.5183\n",
      "model evaluation:  [0.2542271018028259, 0.5183234810829163]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2548 - accuracy: 0.5149 - val_loss: 0.2489 - val_accuracy: 0.5253\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2500 - accuracy: 0.5224 - val_loss: 0.2484 - val_accuracy: 0.5351\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2492 - accuracy: 0.5270 - val_loss: 0.2490 - val_accuracy: 0.5353\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2488 - accuracy: 0.5296 - val_loss: 0.2478 - val_accuracy: 0.5368\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2482 - accuracy: 0.5341 - val_loss: 0.2477 - val_accuracy: 0.5361\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2477 - accuracy: 0.5374 - val_loss: 0.2466 - val_accuracy: 0.5428\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2467 - accuracy: 0.5434 - val_loss: 0.2457 - val_accuracy: 0.5467\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2459 - accuracy: 0.5459 - val_loss: 0.2454 - val_accuracy: 0.5506\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.2450 - accuracy: 0.5498 - val_loss: 0.2448 - val_accuracy: 0.5516\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2443 - accuracy: 0.5515 - val_loss: 0.2437 - val_accuracy: 0.5508\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.2438 - accuracy: 0.5535 - val_loss: 0.2430 - val_accuracy: 0.5548\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2432 - accuracy: 0.5550 - val_loss: 0.2426 - val_accuracy: 0.5576\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2428 - accuracy: 0.5577 - val_loss: 0.2423 - val_accuracy: 0.5599\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2422 - accuracy: 0.5593 - val_loss: 0.2417 - val_accuracy: 0.5607\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2416 - accuracy: 0.5613 - val_loss: 0.2410 - val_accuracy: 0.5652\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2411 - accuracy: 0.5623 - val_loss: 0.2406 - val_accuracy: 0.5639\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2406 - accuracy: 0.5644 - val_loss: 0.2400 - val_accuracy: 0.5669\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2401 - accuracy: 0.5639 - val_loss: 0.2395 - val_accuracy: 0.5693\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2396 - accuracy: 0.5660 - val_loss: 0.2387 - val_accuracy: 0.5691\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2392 - accuracy: 0.5688 - val_loss: 0.2384 - val_accuracy: 0.5708\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2387 - accuracy: 0.5690 - val_loss: 0.2381 - val_accuracy: 0.5705\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2383 - accuracy: 0.5701 - val_loss: 0.2381 - val_accuracy: 0.5713\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2380 - accuracy: 0.5711 - val_loss: 0.2373 - val_accuracy: 0.5746\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2375 - accuracy: 0.5735 - val_loss: 0.2367 - val_accuracy: 0.5748\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2371 - accuracy: 0.5749 - val_loss: 0.2365 - val_accuracy: 0.5764\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2369 - accuracy: 0.5753 - val_loss: 0.2357 - val_accuracy: 0.5791\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2363 - accuracy: 0.5764 - val_loss: 0.2359 - val_accuracy: 0.5784\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2359 - accuracy: 0.5772 - val_loss: 0.2358 - val_accuracy: 0.5808\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2355 - accuracy: 0.5787 - val_loss: 0.2349 - val_accuracy: 0.5813\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2352 - accuracy: 0.5815 - val_loss: 0.2342 - val_accuracy: 0.5844\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2347 - accuracy: 0.5819 - val_loss: 0.2346 - val_accuracy: 0.5818\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2343 - accuracy: 0.5832 - val_loss: 0.2338 - val_accuracy: 0.5844\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2340 - accuracy: 0.5834 - val_loss: 0.2331 - val_accuracy: 0.5868\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2335 - accuracy: 0.5851 - val_loss: 0.2330 - val_accuracy: 0.5858\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2331 - accuracy: 0.5855 - val_loss: 0.2327 - val_accuracy: 0.5867\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.2329 - accuracy: 0.5869 - val_loss: 0.2325 - val_accuracy: 0.5893\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2324 - accuracy: 0.5891 - val_loss: 0.2319 - val_accuracy: 0.5878\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2321 - accuracy: 0.5889 - val_loss: 0.2316 - val_accuracy: 0.5883\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2318 - accuracy: 0.5893 - val_loss: 0.2315 - val_accuracy: 0.5886\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2315 - accuracy: 0.5914 - val_loss: 0.2317 - val_accuracy: 0.5894\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2312 - accuracy: 0.5919 - val_loss: 0.2310 - val_accuracy: 0.5906\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2308 - accuracy: 0.5924 - val_loss: 0.2309 - val_accuracy: 0.5887\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.2306 - accuracy: 0.5928 - val_loss: 0.2311 - val_accuracy: 0.5904\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2302 - accuracy: 0.5938 - val_loss: 0.2305 - val_accuracy: 0.5900\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2300 - accuracy: 0.5936 - val_loss: 0.2306 - val_accuracy: 0.5895\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2298 - accuracy: 0.5955 - val_loss: 0.2303 - val_accuracy: 0.5901\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2297 - accuracy: 0.5961 - val_loss: 0.2306 - val_accuracy: 0.5920\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2293 - accuracy: 0.5972 - val_loss: 0.2303 - val_accuracy: 0.5894\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2289 - accuracy: 0.5986 - val_loss: 0.2301 - val_accuracy: 0.5904\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2286 - accuracy: 0.5994 - val_loss: 0.2301 - val_accuracy: 0.5942\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-6/assets\n",
      "703/703 [==============================] - 1s 1ms/step - loss: 0.2543 - accuracy: 0.5123\n",
      "model evaluation:  [0.25426408648490906, 0.5123481750488281]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2545 - accuracy: 0.5153 - val_loss: 0.2490 - val_accuracy: 0.5277\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2499 - accuracy: 0.5245 - val_loss: 0.2486 - val_accuracy: 0.5301\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2495 - accuracy: 0.5255 - val_loss: 0.2482 - val_accuracy: 0.5379\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2488 - accuracy: 0.5316 - val_loss: 0.2479 - val_accuracy: 0.5376\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2482 - accuracy: 0.5366 - val_loss: 0.2473 - val_accuracy: 0.5416\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.2475 - accuracy: 0.5387 - val_loss: 0.2468 - val_accuracy: 0.5437\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2470 - accuracy: 0.5418 - val_loss: 0.2463 - val_accuracy: 0.5463\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2464 - accuracy: 0.5438 - val_loss: 0.2459 - val_accuracy: 0.5475\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.2458 - accuracy: 0.5484 - val_loss: 0.2453 - val_accuracy: 0.5542\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2452 - accuracy: 0.5497 - val_loss: 0.2446 - val_accuracy: 0.5543\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2447 - accuracy: 0.5516 - val_loss: 0.2442 - val_accuracy: 0.5522\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2442 - accuracy: 0.5535 - val_loss: 0.2436 - val_accuracy: 0.5577\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2436 - accuracy: 0.5546 - val_loss: 0.2432 - val_accuracy: 0.5551\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2431 - accuracy: 0.5556 - val_loss: 0.2427 - val_accuracy: 0.5586\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2425 - accuracy: 0.5573 - val_loss: 0.2418 - val_accuracy: 0.5569\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2418 - accuracy: 0.5596 - val_loss: 0.2411 - val_accuracy: 0.5606\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2411 - accuracy: 0.5622 - val_loss: 0.2409 - val_accuracy: 0.5613\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2405 - accuracy: 0.5635 - val_loss: 0.2399 - val_accuracy: 0.5624\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2400 - accuracy: 0.5646 - val_loss: 0.2401 - val_accuracy: 0.5645\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2395 - accuracy: 0.5668 - val_loss: 0.2391 - val_accuracy: 0.5642\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2388 - accuracy: 0.5676 - val_loss: 0.2388 - val_accuracy: 0.5673\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2384 - accuracy: 0.5706 - val_loss: 0.2384 - val_accuracy: 0.5673\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2377 - accuracy: 0.5723 - val_loss: 0.2377 - val_accuracy: 0.5677\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2372 - accuracy: 0.5732 - val_loss: 0.2369 - val_accuracy: 0.5722\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2369 - accuracy: 0.5744 - val_loss: 0.2367 - val_accuracy: 0.5744\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2363 - accuracy: 0.5754 - val_loss: 0.2361 - val_accuracy: 0.5772\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2358 - accuracy: 0.5769 - val_loss: 0.2356 - val_accuracy: 0.5766\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2352 - accuracy: 0.5801 - val_loss: 0.2353 - val_accuracy: 0.5785\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2345 - accuracy: 0.5819 - val_loss: 0.2346 - val_accuracy: 0.5814\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2341 - accuracy: 0.5833 - val_loss: 0.2342 - val_accuracy: 0.5804\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2335 - accuracy: 0.5839 - val_loss: 0.2340 - val_accuracy: 0.5846\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2330 - accuracy: 0.5855 - val_loss: 0.2337 - val_accuracy: 0.5821\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2327 - accuracy: 0.5871 - val_loss: 0.2324 - val_accuracy: 0.5865\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 19s 23ms/step - loss: 0.2321 - accuracy: 0.5884 - val_loss: 0.2323 - val_accuracy: 0.5888\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2317 - accuracy: 0.5897 - val_loss: 0.2322 - val_accuracy: 0.5876\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2310 - accuracy: 0.5914 - val_loss: 0.2319 - val_accuracy: 0.5912\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2305 - accuracy: 0.5932 - val_loss: 0.2317 - val_accuracy: 0.5914\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 19s 23ms/step - loss: 0.2303 - accuracy: 0.5935 - val_loss: 0.2310 - val_accuracy: 0.5893\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2298 - accuracy: 0.5954 - val_loss: 0.2313 - val_accuracy: 0.5932\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2295 - accuracy: 0.5974 - val_loss: 0.2308 - val_accuracy: 0.5905\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2289 - accuracy: 0.5991 - val_loss: 0.2302 - val_accuracy: 0.5934\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2286 - accuracy: 0.5988 - val_loss: 0.2299 - val_accuracy: 0.5946\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.2282 - accuracy: 0.5995 - val_loss: 0.2298 - val_accuracy: 0.5932\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2277 - accuracy: 0.6023 - val_loss: 0.2292 - val_accuracy: 0.5941\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2275 - accuracy: 0.6020 - val_loss: 0.2293 - val_accuracy: 0.5956\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.2272 - accuracy: 0.6027 - val_loss: 0.2287 - val_accuracy: 0.5968\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2268 - accuracy: 0.6045 - val_loss: 0.2290 - val_accuracy: 0.5974\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2264 - accuracy: 0.6042 - val_loss: 0.2284 - val_accuracy: 0.5980\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2263 - accuracy: 0.6059 - val_loss: 0.2282 - val_accuracy: 0.5984\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2257 - accuracy: 0.6076 - val_loss: 0.2279 - val_accuracy: 0.6000\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-7/assets\n",
      "687/687 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.5108\n",
      "model evaluation:  [0.2560282051563263, 0.5108329653739929]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2547 - accuracy: 0.5149 - val_loss: 0.2488 - val_accuracy: 0.5311\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2501 - accuracy: 0.5212 - val_loss: 0.2491 - val_accuracy: 0.5252\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2495 - accuracy: 0.5254 - val_loss: 0.2488 - val_accuracy: 0.5325\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2491 - accuracy: 0.5276 - val_loss: 0.2486 - val_accuracy: 0.5286\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2487 - accuracy: 0.5320 - val_loss: 0.2478 - val_accuracy: 0.5385\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2481 - accuracy: 0.5354 - val_loss: 0.2475 - val_accuracy: 0.5376\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2476 - accuracy: 0.5384 - val_loss: 0.2472 - val_accuracy: 0.5435\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2469 - accuracy: 0.5422 - val_loss: 0.2461 - val_accuracy: 0.5449\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2459 - accuracy: 0.5458 - val_loss: 0.2450 - val_accuracy: 0.5513\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2449 - accuracy: 0.5492 - val_loss: 0.2442 - val_accuracy: 0.5480\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.2440 - accuracy: 0.5513 - val_loss: 0.2437 - val_accuracy: 0.5522\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2432 - accuracy: 0.5531 - val_loss: 0.2423 - val_accuracy: 0.5573\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2425 - accuracy: 0.5552 - val_loss: 0.2417 - val_accuracy: 0.5595\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2417 - accuracy: 0.5588 - val_loss: 0.2413 - val_accuracy: 0.5620\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2410 - accuracy: 0.5605 - val_loss: 0.2404 - val_accuracy: 0.5631\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2405 - accuracy: 0.5626 - val_loss: 0.2397 - val_accuracy: 0.5664\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2400 - accuracy: 0.5638 - val_loss: 0.2392 - val_accuracy: 0.5681\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2394 - accuracy: 0.5659 - val_loss: 0.2388 - val_accuracy: 0.5685\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2389 - accuracy: 0.5671 - val_loss: 0.2379 - val_accuracy: 0.5714\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2383 - accuracy: 0.5706 - val_loss: 0.2375 - val_accuracy: 0.5719\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2378 - accuracy: 0.5714 - val_loss: 0.2370 - val_accuracy: 0.5729\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2372 - accuracy: 0.5734 - val_loss: 0.2366 - val_accuracy: 0.5744\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2366 - accuracy: 0.5757 - val_loss: 0.2367 - val_accuracy: 0.5743\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2360 - accuracy: 0.5763 - val_loss: 0.2356 - val_accuracy: 0.5753\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2354 - accuracy: 0.5786 - val_loss: 0.2347 - val_accuracy: 0.5778\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2348 - accuracy: 0.5800 - val_loss: 0.2343 - val_accuracy: 0.5780\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2342 - accuracy: 0.5828 - val_loss: 0.2339 - val_accuracy: 0.5809\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2338 - accuracy: 0.5826 - val_loss: 0.2329 - val_accuracy: 0.5798\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2332 - accuracy: 0.5853 - val_loss: 0.2338 - val_accuracy: 0.5814\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2328 - accuracy: 0.5861 - val_loss: 0.2322 - val_accuracy: 0.5829\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2322 - accuracy: 0.5866 - val_loss: 0.2328 - val_accuracy: 0.5827\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2318 - accuracy: 0.5885 - val_loss: 0.2319 - val_accuracy: 0.5846\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2313 - accuracy: 0.5900 - val_loss: 0.2317 - val_accuracy: 0.5868\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2310 - accuracy: 0.5905 - val_loss: 0.2308 - val_accuracy: 0.5860\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.2304 - accuracy: 0.5932 - val_loss: 0.2308 - val_accuracy: 0.5875\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2301 - accuracy: 0.5930 - val_loss: 0.2307 - val_accuracy: 0.5873\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2296 - accuracy: 0.5938 - val_loss: 0.2301 - val_accuracy: 0.5907\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2292 - accuracy: 0.5965 - val_loss: 0.2298 - val_accuracy: 0.5882\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2289 - accuracy: 0.5967 - val_loss: 0.2298 - val_accuracy: 0.5880\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2284 - accuracy: 0.5972 - val_loss: 0.2295 - val_accuracy: 0.5915\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2281 - accuracy: 0.5989 - val_loss: 0.2295 - val_accuracy: 0.5887\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2275 - accuracy: 0.6003 - val_loss: 0.2294 - val_accuracy: 0.5902\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2271 - accuracy: 0.6016 - val_loss: 0.2287 - val_accuracy: 0.5942\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2268 - accuracy: 0.6027 - val_loss: 0.2290 - val_accuracy: 0.5919\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2264 - accuracy: 0.6045 - val_loss: 0.2285 - val_accuracy: 0.5918\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2261 - accuracy: 0.6050 - val_loss: 0.2288 - val_accuracy: 0.5944\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2255 - accuracy: 0.6065 - val_loss: 0.2279 - val_accuracy: 0.5928\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2255 - accuracy: 0.6070 - val_loss: 0.2279 - val_accuracy: 0.5984\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2250 - accuracy: 0.6077 - val_loss: 0.2280 - val_accuracy: 0.5964\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2246 - accuracy: 0.6082 - val_loss: 0.2276 - val_accuracy: 0.5980\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-8/assets\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.5221\n",
      "model evaluation:  [0.2545868754386902, 0.5221036672592163]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2548 - accuracy: 0.5141 - val_loss: 0.2487 - val_accuracy: 0.5290\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2500 - accuracy: 0.5218 - val_loss: 0.2483 - val_accuracy: 0.5336\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2492 - accuracy: 0.5276 - val_loss: 0.2483 - val_accuracy: 0.5318\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2487 - accuracy: 0.5312 - val_loss: 0.2485 - val_accuracy: 0.5316\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2481 - accuracy: 0.5355 - val_loss: 0.2474 - val_accuracy: 0.5414\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2476 - accuracy: 0.5370 - val_loss: 0.2472 - val_accuracy: 0.5428\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2470 - accuracy: 0.5419 - val_loss: 0.2465 - val_accuracy: 0.5453\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2464 - accuracy: 0.5433 - val_loss: 0.2459 - val_accuracy: 0.5456\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2458 - accuracy: 0.5463 - val_loss: 0.2459 - val_accuracy: 0.5464\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2452 - accuracy: 0.5473 - val_loss: 0.2448 - val_accuracy: 0.5478\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2447 - accuracy: 0.5496 - val_loss: 0.2440 - val_accuracy: 0.5516\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2437 - accuracy: 0.5518 - val_loss: 0.2431 - val_accuracy: 0.5562\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.2424 - accuracy: 0.5566 - val_loss: 0.2419 - val_accuracy: 0.5587\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2412 - accuracy: 0.5587 - val_loss: 0.2408 - val_accuracy: 0.5618\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2405 - accuracy: 0.5620 - val_loss: 0.2401 - val_accuracy: 0.5620\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2397 - accuracy: 0.5639 - val_loss: 0.2402 - val_accuracy: 0.5627\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2390 - accuracy: 0.5666 - val_loss: 0.2396 - val_accuracy: 0.5624\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2386 - accuracy: 0.5685 - val_loss: 0.2399 - val_accuracy: 0.5646\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2378 - accuracy: 0.5703 - val_loss: 0.2387 - val_accuracy: 0.5663\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2374 - accuracy: 0.5712 - val_loss: 0.2377 - val_accuracy: 0.5703\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2368 - accuracy: 0.5739 - val_loss: 0.2371 - val_accuracy: 0.5715\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2362 - accuracy: 0.5766 - val_loss: 0.2362 - val_accuracy: 0.5737\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2354 - accuracy: 0.5795 - val_loss: 0.2361 - val_accuracy: 0.5776\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2348 - accuracy: 0.5809 - val_loss: 0.2349 - val_accuracy: 0.5790\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2340 - accuracy: 0.5820 - val_loss: 0.2341 - val_accuracy: 0.5828\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2334 - accuracy: 0.5851 - val_loss: 0.2337 - val_accuracy: 0.5790\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2328 - accuracy: 0.5861 - val_loss: 0.2332 - val_accuracy: 0.5850\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2323 - accuracy: 0.5875 - val_loss: 0.2326 - val_accuracy: 0.5845\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2316 - accuracy: 0.5886 - val_loss: 0.2320 - val_accuracy: 0.5873\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2311 - accuracy: 0.5910 - val_loss: 0.2313 - val_accuracy: 0.5906\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2306 - accuracy: 0.5918 - val_loss: 0.2310 - val_accuracy: 0.5890\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2301 - accuracy: 0.5940 - val_loss: 0.2302 - val_accuracy: 0.5925\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2296 - accuracy: 0.5940 - val_loss: 0.2305 - val_accuracy: 0.5917\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2291 - accuracy: 0.5969 - val_loss: 0.2300 - val_accuracy: 0.5916\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2286 - accuracy: 0.5976 - val_loss: 0.2292 - val_accuracy: 0.5952\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2282 - accuracy: 0.5988 - val_loss: 0.2289 - val_accuracy: 0.5949\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2277 - accuracy: 0.6003 - val_loss: 0.2286 - val_accuracy: 0.5953\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2273 - accuracy: 0.6014 - val_loss: 0.2280 - val_accuracy: 0.5994\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2268 - accuracy: 0.6022 - val_loss: 0.2282 - val_accuracy: 0.5990\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2263 - accuracy: 0.6040 - val_loss: 0.2283 - val_accuracy: 0.5971\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2261 - accuracy: 0.6047 - val_loss: 0.2280 - val_accuracy: 0.5999\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2256 - accuracy: 0.6061 - val_loss: 0.2275 - val_accuracy: 0.6017\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2251 - accuracy: 0.6070 - val_loss: 0.2271 - val_accuracy: 0.6019\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.2248 - accuracy: 0.6078 - val_loss: 0.2275 - val_accuracy: 0.5999\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2244 - accuracy: 0.6097 - val_loss: 0.2265 - val_accuracy: 0.6015\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2240 - accuracy: 0.6108 - val_loss: 0.2268 - val_accuracy: 0.6026\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2237 - accuracy: 0.6119 - val_loss: 0.2265 - val_accuracy: 0.6023\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2232 - accuracy: 0.6126 - val_loss: 0.2268 - val_accuracy: 0.6034\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2230 - accuracy: 0.6144 - val_loss: 0.2263 - val_accuracy: 0.6047\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.2225 - accuracy: 0.6144 - val_loss: 0.2260 - val_accuracy: 0.6045\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-9/assets\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.5192\n",
      "model evaluation:  [0.25611764192581177, 0.5191757082939148]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2545 - accuracy: 0.5143 - val_loss: 0.2488 - val_accuracy: 0.5293\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2499 - accuracy: 0.5217 - val_loss: 0.2482 - val_accuracy: 0.5348\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2491 - accuracy: 0.5277 - val_loss: 0.2480 - val_accuracy: 0.5350\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2486 - accuracy: 0.5304 - val_loss: 0.2476 - val_accuracy: 0.5364\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2481 - accuracy: 0.5334 - val_loss: 0.2480 - val_accuracy: 0.5360\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2477 - accuracy: 0.5351 - val_loss: 0.2472 - val_accuracy: 0.5392\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2471 - accuracy: 0.5389 - val_loss: 0.2469 - val_accuracy: 0.5402\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2465 - accuracy: 0.5438 - val_loss: 0.2460 - val_accuracy: 0.5491\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2459 - accuracy: 0.5449 - val_loss: 0.2452 - val_accuracy: 0.5467\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2452 - accuracy: 0.5472 - val_loss: 0.2449 - val_accuracy: 0.5431\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2442 - accuracy: 0.5519 - val_loss: 0.2433 - val_accuracy: 0.5512\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2430 - accuracy: 0.5550 - val_loss: 0.2421 - val_accuracy: 0.5589\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2419 - accuracy: 0.5598 - val_loss: 0.2413 - val_accuracy: 0.5600\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 19s 23ms/step - loss: 0.2410 - accuracy: 0.5614 - val_loss: 0.2400 - val_accuracy: 0.5631\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2401 - accuracy: 0.5639 - val_loss: 0.2394 - val_accuracy: 0.5682\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2393 - accuracy: 0.5661 - val_loss: 0.2388 - val_accuracy: 0.5659\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2387 - accuracy: 0.5671 - val_loss: 0.2387 - val_accuracy: 0.5680\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2380 - accuracy: 0.5687 - val_loss: 0.2378 - val_accuracy: 0.5702\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2376 - accuracy: 0.5708 - val_loss: 0.2376 - val_accuracy: 0.5693\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2371 - accuracy: 0.5707 - val_loss: 0.2370 - val_accuracy: 0.5721\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2365 - accuracy: 0.5728 - val_loss: 0.2368 - val_accuracy: 0.5732\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 26s 33ms/step - loss: 0.2360 - accuracy: 0.5727 - val_loss: 0.2364 - val_accuracy: 0.5750\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2355 - accuracy: 0.5751 - val_loss: 0.2360 - val_accuracy: 0.5715\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2350 - accuracy: 0.5759 - val_loss: 0.2356 - val_accuracy: 0.5750\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 26s 33ms/step - loss: 0.2346 - accuracy: 0.5791 - val_loss: 0.2355 - val_accuracy: 0.5753\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2342 - accuracy: 0.5789 - val_loss: 0.2352 - val_accuracy: 0.5764\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2335 - accuracy: 0.5808 - val_loss: 0.2338 - val_accuracy: 0.5810\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2330 - accuracy: 0.5820 - val_loss: 0.2332 - val_accuracy: 0.5821\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.2324 - accuracy: 0.5829 - val_loss: 0.2331 - val_accuracy: 0.5846\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2319 - accuracy: 0.5856 - val_loss: 0.2329 - val_accuracy: 0.5849\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2313 - accuracy: 0.5875 - val_loss: 0.2323 - val_accuracy: 0.5851\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2309 - accuracy: 0.5888 - val_loss: 0.2312 - val_accuracy: 0.5887\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2302 - accuracy: 0.5907 - val_loss: 0.2310 - val_accuracy: 0.5920\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2297 - accuracy: 0.5939 - val_loss: 0.2308 - val_accuracy: 0.5907\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2290 - accuracy: 0.5944 - val_loss: 0.2312 - val_accuracy: 0.5939\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2287 - accuracy: 0.5965 - val_loss: 0.2296 - val_accuracy: 0.5963\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2281 - accuracy: 0.5973 - val_loss: 0.2288 - val_accuracy: 0.5986\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2277 - accuracy: 0.5993 - val_loss: 0.2290 - val_accuracy: 0.5961\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2271 - accuracy: 0.6005 - val_loss: 0.2285 - val_accuracy: 0.5987\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2267 - accuracy: 0.6023 - val_loss: 0.2283 - val_accuracy: 0.6003\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 19s 23ms/step - loss: 0.2263 - accuracy: 0.6024 - val_loss: 0.2280 - val_accuracy: 0.5996\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2258 - accuracy: 0.6042 - val_loss: 0.2277 - val_accuracy: 0.6015\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2253 - accuracy: 0.6053 - val_loss: 0.2277 - val_accuracy: 0.6016\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.2249 - accuracy: 0.6073 - val_loss: 0.2275 - val_accuracy: 0.6009\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.2244 - accuracy: 0.6087 - val_loss: 0.2270 - val_accuracy: 0.6056\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2238 - accuracy: 0.6110 - val_loss: 0.2264 - val_accuracy: 0.6061\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2237 - accuracy: 0.6102 - val_loss: 0.2271 - val_accuracy: 0.6039\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2232 - accuracy: 0.6112 - val_loss: 0.2256 - val_accuracy: 0.6072\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2228 - accuracy: 0.6124 - val_loss: 0.2262 - val_accuracy: 0.6085\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2224 - accuracy: 0.6141 - val_loss: 0.2263 - val_accuracy: 0.6074\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-10/assets\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.5045\n",
      "model evaluation:  [0.2578260600566864, 0.5045450329780579]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2543 - accuracy: 0.5147 - val_loss: 0.2492 - val_accuracy: 0.5274\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.2499 - accuracy: 0.5239 - val_loss: 0.2495 - val_accuracy: 0.5282\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2491 - accuracy: 0.5279 - val_loss: 0.2478 - val_accuracy: 0.5372\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2486 - accuracy: 0.5313 - val_loss: 0.2476 - val_accuracy: 0.5414\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2479 - accuracy: 0.5353 - val_loss: 0.2473 - val_accuracy: 0.5397\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2472 - accuracy: 0.5396 - val_loss: 0.2464 - val_accuracy: 0.5435\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 26s 32ms/step - loss: 0.2466 - accuracy: 0.5401 - val_loss: 0.2463 - val_accuracy: 0.5445\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2460 - accuracy: 0.5448 - val_loss: 0.2455 - val_accuracy: 0.5470\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2454 - accuracy: 0.5462 - val_loss: 0.2448 - val_accuracy: 0.5516\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.2447 - accuracy: 0.5485 - val_loss: 0.2438 - val_accuracy: 0.5535\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2438 - accuracy: 0.5512 - val_loss: 0.2430 - val_accuracy: 0.5542\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2424 - accuracy: 0.5558 - val_loss: 0.2415 - val_accuracy: 0.5609\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2414 - accuracy: 0.5581 - val_loss: 0.2415 - val_accuracy: 0.5593\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2406 - accuracy: 0.5607 - val_loss: 0.2407 - val_accuracy: 0.5594\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 26s 33ms/step - loss: 0.2398 - accuracy: 0.5626 - val_loss: 0.2393 - val_accuracy: 0.5634\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 26s 32ms/step - loss: 0.2390 - accuracy: 0.5649 - val_loss: 0.2387 - val_accuracy: 0.5658\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2383 - accuracy: 0.5669 - val_loss: 0.2378 - val_accuracy: 0.5663\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2374 - accuracy: 0.5697 - val_loss: 0.2370 - val_accuracy: 0.5707\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2366 - accuracy: 0.5713 - val_loss: 0.2365 - val_accuracy: 0.5747\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2360 - accuracy: 0.5730 - val_loss: 0.2359 - val_accuracy: 0.5759\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2352 - accuracy: 0.5763 - val_loss: 0.2352 - val_accuracy: 0.5746\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2344 - accuracy: 0.5773 - val_loss: 0.2346 - val_accuracy: 0.5770\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2339 - accuracy: 0.5793 - val_loss: 0.2339 - val_accuracy: 0.5781\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2332 - accuracy: 0.5812 - val_loss: 0.2328 - val_accuracy: 0.5840\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 27s 33ms/step - loss: 0.2325 - accuracy: 0.5838 - val_loss: 0.2327 - val_accuracy: 0.5829\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.2318 - accuracy: 0.5849 - val_loss: 0.2323 - val_accuracy: 0.5834\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2310 - accuracy: 0.5872 - val_loss: 0.2317 - val_accuracy: 0.5829\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2304 - accuracy: 0.5883 - val_loss: 0.2312 - val_accuracy: 0.5863\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.2298 - accuracy: 0.5907 - val_loss: 0.2304 - val_accuracy: 0.5886\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2293 - accuracy: 0.5919 - val_loss: 0.2301 - val_accuracy: 0.5864\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2287 - accuracy: 0.5940 - val_loss: 0.2297 - val_accuracy: 0.5902\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2282 - accuracy: 0.5953 - val_loss: 0.2287 - val_accuracy: 0.5945\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.2276 - accuracy: 0.5962 - val_loss: 0.2282 - val_accuracy: 0.5966\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2270 - accuracy: 0.5984 - val_loss: 0.2286 - val_accuracy: 0.5956\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2264 - accuracy: 0.6000 - val_loss: 0.2281 - val_accuracy: 0.5942\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2261 - accuracy: 0.6004 - val_loss: 0.2276 - val_accuracy: 0.5963\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2254 - accuracy: 0.6024 - val_loss: 0.2280 - val_accuracy: 0.5937\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2251 - accuracy: 0.6044 - val_loss: 0.2265 - val_accuracy: 0.6003\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2246 - accuracy: 0.6056 - val_loss: 0.2264 - val_accuracy: 0.6016\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2241 - accuracy: 0.6080 - val_loss: 0.2261 - val_accuracy: 0.6030\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2236 - accuracy: 0.6085 - val_loss: 0.2263 - val_accuracy: 0.6021\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2232 - accuracy: 0.6100 - val_loss: 0.2256 - val_accuracy: 0.6004\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2227 - accuracy: 0.6116 - val_loss: 0.2255 - val_accuracy: 0.6011\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2226 - accuracy: 0.6107 - val_loss: 0.2251 - val_accuracy: 0.6029\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2218 - accuracy: 0.6148 - val_loss: 0.2248 - val_accuracy: 0.6050\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2214 - accuracy: 0.6156 - val_loss: 0.2256 - val_accuracy: 0.6056\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2210 - accuracy: 0.6160 - val_loss: 0.2249 - val_accuracy: 0.6044\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.2205 - accuracy: 0.6187 - val_loss: 0.2249 - val_accuracy: 0.6070\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2201 - accuracy: 0.6190 - val_loss: 0.2250 - val_accuracy: 0.6063\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.2201 - accuracy: 0.6191 - val_loss: 0.2243 - val_accuracy: 0.6074\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-11/assets\n",
      "624/624 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.5090\n",
      "model evaluation:  [0.25848427414894104, 0.508967936038971]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2542 - accuracy: 0.5147 - val_loss: 0.2494 - val_accuracy: 0.5196\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2500 - accuracy: 0.5220 - val_loss: 0.2484 - val_accuracy: 0.5364\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2492 - accuracy: 0.5293 - val_loss: 0.2484 - val_accuracy: 0.5355\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2483 - accuracy: 0.5325 - val_loss: 0.2472 - val_accuracy: 0.5397\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2477 - accuracy: 0.5342 - val_loss: 0.2469 - val_accuracy: 0.5432\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2469 - accuracy: 0.5394 - val_loss: 0.2465 - val_accuracy: 0.5444\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2465 - accuracy: 0.5420 - val_loss: 0.2455 - val_accuracy: 0.5481\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2458 - accuracy: 0.5455 - val_loss: 0.2452 - val_accuracy: 0.5529\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2453 - accuracy: 0.5470 - val_loss: 0.2445 - val_accuracy: 0.5507\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2445 - accuracy: 0.5495 - val_loss: 0.2435 - val_accuracy: 0.5508\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2437 - accuracy: 0.5532 - val_loss: 0.2435 - val_accuracy: 0.5538\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2425 - accuracy: 0.5567 - val_loss: 0.2423 - val_accuracy: 0.5587\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2415 - accuracy: 0.5592 - val_loss: 0.2413 - val_accuracy: 0.5606\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2405 - accuracy: 0.5614 - val_loss: 0.2403 - val_accuracy: 0.5626\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2397 - accuracy: 0.5636 - val_loss: 0.2393 - val_accuracy: 0.5670\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2389 - accuracy: 0.5669 - val_loss: 0.2386 - val_accuracy: 0.5673\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2381 - accuracy: 0.5683 - val_loss: 0.2378 - val_accuracy: 0.5702\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2373 - accuracy: 0.5708 - val_loss: 0.2368 - val_accuracy: 0.5681\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2365 - accuracy: 0.5724 - val_loss: 0.2364 - val_accuracy: 0.5721\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2358 - accuracy: 0.5743 - val_loss: 0.2356 - val_accuracy: 0.5752\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2352 - accuracy: 0.5766 - val_loss: 0.2358 - val_accuracy: 0.5721\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2345 - accuracy: 0.5780 - val_loss: 0.2342 - val_accuracy: 0.5785\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2340 - accuracy: 0.5801 - val_loss: 0.2339 - val_accuracy: 0.5800\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2332 - accuracy: 0.5822 - val_loss: 0.2334 - val_accuracy: 0.5812\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2327 - accuracy: 0.5823 - val_loss: 0.2330 - val_accuracy: 0.5823\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2322 - accuracy: 0.5846 - val_loss: 0.2323 - val_accuracy: 0.5841\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2315 - accuracy: 0.5865 - val_loss: 0.2317 - val_accuracy: 0.5880\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2310 - accuracy: 0.5883 - val_loss: 0.2317 - val_accuracy: 0.5864\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2304 - accuracy: 0.5892 - val_loss: 0.2310 - val_accuracy: 0.5890\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2300 - accuracy: 0.5920 - val_loss: 0.2300 - val_accuracy: 0.5918\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2294 - accuracy: 0.5927 - val_loss: 0.2299 - val_accuracy: 0.5934\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2288 - accuracy: 0.5941 - val_loss: 0.2296 - val_accuracy: 0.5944\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2285 - accuracy: 0.5945 - val_loss: 0.2290 - val_accuracy: 0.5934\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2278 - accuracy: 0.5968 - val_loss: 0.2288 - val_accuracy: 0.5943\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2273 - accuracy: 0.5980 - val_loss: 0.2288 - val_accuracy: 0.5958\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2269 - accuracy: 0.6001 - val_loss: 0.2283 - val_accuracy: 0.5976\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2264 - accuracy: 0.6016 - val_loss: 0.2282 - val_accuracy: 0.5943\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2260 - accuracy: 0.6016 - val_loss: 0.2285 - val_accuracy: 0.5954\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2254 - accuracy: 0.6041 - val_loss: 0.2274 - val_accuracy: 0.5958\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2250 - accuracy: 0.6051 - val_loss: 0.2276 - val_accuracy: 0.5961\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2245 - accuracy: 0.6062 - val_loss: 0.2282 - val_accuracy: 0.5986\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2240 - accuracy: 0.6076 - val_loss: 0.2278 - val_accuracy: 0.5969\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2236 - accuracy: 0.6084 - val_loss: 0.2265 - val_accuracy: 0.6020\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2231 - accuracy: 0.6100 - val_loss: 0.2279 - val_accuracy: 0.6000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2227 - accuracy: 0.6113 - val_loss: 0.2269 - val_accuracy: 0.5996\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 29s 36ms/step - loss: 0.2222 - accuracy: 0.6132 - val_loss: 0.2265 - val_accuracy: 0.5991\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2218 - accuracy: 0.6145 - val_loss: 0.2264 - val_accuracy: 0.6016\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.2213 - accuracy: 0.6160 - val_loss: 0.2263 - val_accuracy: 0.5992\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2208 - accuracy: 0.6168 - val_loss: 0.2269 - val_accuracy: 0.6008\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 26s 32ms/step - loss: 0.2204 - accuracy: 0.6179 - val_loss: 0.2267 - val_accuracy: 0.6012\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-12/assets\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.5160\n",
      "model evaluation:  [0.256908118724823, 0.5160345435142517]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 30s 37ms/step - loss: 0.2538 - accuracy: 0.5162 - val_loss: 0.2483 - val_accuracy: 0.5316\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2495 - accuracy: 0.5268 - val_loss: 0.2483 - val_accuracy: 0.5330\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2488 - accuracy: 0.5311 - val_loss: 0.2478 - val_accuracy: 0.5361\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2482 - accuracy: 0.5333 - val_loss: 0.2477 - val_accuracy: 0.5356\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2475 - accuracy: 0.5378 - val_loss: 0.2470 - val_accuracy: 0.5442\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2470 - accuracy: 0.5400 - val_loss: 0.2465 - val_accuracy: 0.5414\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2462 - accuracy: 0.5438 - val_loss: 0.2452 - val_accuracy: 0.5478\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2453 - accuracy: 0.5464 - val_loss: 0.2444 - val_accuracy: 0.5505\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2446 - accuracy: 0.5497 - val_loss: 0.2438 - val_accuracy: 0.5533\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2438 - accuracy: 0.5528 - val_loss: 0.2436 - val_accuracy: 0.5520\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2432 - accuracy: 0.5536 - val_loss: 0.2431 - val_accuracy: 0.5577\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2424 - accuracy: 0.5563 - val_loss: 0.2422 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2416 - accuracy: 0.5592 - val_loss: 0.2419 - val_accuracy: 0.5590\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2409 - accuracy: 0.5609 - val_loss: 0.2405 - val_accuracy: 0.5637\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2402 - accuracy: 0.5629 - val_loss: 0.2401 - val_accuracy: 0.5627\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2394 - accuracy: 0.5654 - val_loss: 0.2395 - val_accuracy: 0.5618\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2387 - accuracy: 0.5673 - val_loss: 0.2385 - val_accuracy: 0.5638\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2377 - accuracy: 0.5699 - val_loss: 0.2378 - val_accuracy: 0.5654\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2369 - accuracy: 0.5718 - val_loss: 0.2373 - val_accuracy: 0.5682\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2362 - accuracy: 0.5743 - val_loss: 0.2360 - val_accuracy: 0.5705\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2355 - accuracy: 0.5766 - val_loss: 0.2364 - val_accuracy: 0.5710\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2349 - accuracy: 0.5772 - val_loss: 0.2353 - val_accuracy: 0.5729\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2342 - accuracy: 0.5794 - val_loss: 0.2347 - val_accuracy: 0.5741\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2337 - accuracy: 0.5813 - val_loss: 0.2344 - val_accuracy: 0.5757\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2330 - accuracy: 0.5829 - val_loss: 0.2338 - val_accuracy: 0.5778\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2325 - accuracy: 0.5848 - val_loss: 0.2338 - val_accuracy: 0.5781\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2318 - accuracy: 0.5850 - val_loss: 0.2331 - val_accuracy: 0.5804\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2312 - accuracy: 0.5868 - val_loss: 0.2322 - val_accuracy: 0.5856\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2307 - accuracy: 0.5889 - val_loss: 0.2325 - val_accuracy: 0.5827\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2302 - accuracy: 0.5908 - val_loss: 0.2315 - val_accuracy: 0.5874\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2296 - accuracy: 0.5920 - val_loss: 0.2314 - val_accuracy: 0.5880\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2291 - accuracy: 0.5937 - val_loss: 0.2310 - val_accuracy: 0.5885\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2286 - accuracy: 0.5939 - val_loss: 0.2309 - val_accuracy: 0.5883\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2281 - accuracy: 0.5974 - val_loss: 0.2307 - val_accuracy: 0.5884\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2276 - accuracy: 0.5986 - val_loss: 0.2301 - val_accuracy: 0.5918\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2272 - accuracy: 0.5982 - val_loss: 0.2305 - val_accuracy: 0.5938\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2268 - accuracy: 0.6008 - val_loss: 0.2294 - val_accuracy: 0.5936\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2262 - accuracy: 0.6019 - val_loss: 0.2290 - val_accuracy: 0.5949\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2256 - accuracy: 0.6037 - val_loss: 0.2296 - val_accuracy: 0.5958\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2254 - accuracy: 0.6046 - val_loss: 0.2284 - val_accuracy: 0.5993\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2247 - accuracy: 0.6066 - val_loss: 0.2295 - val_accuracy: 0.5993\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2245 - accuracy: 0.6072 - val_loss: 0.2284 - val_accuracy: 0.5974\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2239 - accuracy: 0.6094 - val_loss: 0.2276 - val_accuracy: 0.5972\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2234 - accuracy: 0.6095 - val_loss: 0.2275 - val_accuracy: 0.6013\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2230 - accuracy: 0.6113 - val_loss: 0.2275 - val_accuracy: 0.5982\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2226 - accuracy: 0.6132 - val_loss: 0.2281 - val_accuracy: 0.6019\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2222 - accuracy: 0.6143 - val_loss: 0.2269 - val_accuracy: 0.6010\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2218 - accuracy: 0.6153 - val_loss: 0.2274 - val_accuracy: 0.5998\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2216 - accuracy: 0.6159 - val_loss: 0.2275 - val_accuracy: 0.6028\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 20s 24ms/step - loss: 0.2210 - accuracy: 0.6179 - val_loss: 0.2270 - val_accuracy: 0.6025\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-13/assets\n",
      "593/593 [==============================] - 2s 3ms/step - loss: 0.2546 - accuracy: 0.5227\n",
      "model evaluation:  [0.25458675622940063, 0.5226840972900391]\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2538 - accuracy: 0.5179 - val_loss: 0.2485 - val_accuracy: 0.5289\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2497 - accuracy: 0.5244 - val_loss: 0.2483 - val_accuracy: 0.5327\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2493 - accuracy: 0.5263 - val_loss: 0.2481 - val_accuracy: 0.5365\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2484 - accuracy: 0.5310 - val_loss: 0.2472 - val_accuracy: 0.5435\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2477 - accuracy: 0.5352 - val_loss: 0.2472 - val_accuracy: 0.5381\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2471 - accuracy: 0.5388 - val_loss: 0.2471 - val_accuracy: 0.5379\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2465 - accuracy: 0.5415 - val_loss: 0.2460 - val_accuracy: 0.5472\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2459 - accuracy: 0.5441 - val_loss: 0.2452 - val_accuracy: 0.5498\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2453 - accuracy: 0.5464 - val_loss: 0.2445 - val_accuracy: 0.5505\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2448 - accuracy: 0.5480 - val_loss: 0.2438 - val_accuracy: 0.5542\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2441 - accuracy: 0.5507 - val_loss: 0.2431 - val_accuracy: 0.5565\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 27s 34ms/step - loss: 0.2432 - accuracy: 0.5537 - val_loss: 0.2421 - val_accuracy: 0.5596\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2422 - accuracy: 0.5576 - val_loss: 0.2417 - val_accuracy: 0.5597\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2412 - accuracy: 0.5602 - val_loss: 0.2408 - val_accuracy: 0.5582\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2401 - accuracy: 0.5614 - val_loss: 0.2391 - val_accuracy: 0.5667\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.2389 - accuracy: 0.5659 - val_loss: 0.2376 - val_accuracy: 0.5696\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2378 - accuracy: 0.5680 - val_loss: 0.2371 - val_accuracy: 0.5705\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.2370 - accuracy: 0.5710 - val_loss: 0.2362 - val_accuracy: 0.5715\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2361 - accuracy: 0.5735 - val_loss: 0.2357 - val_accuracy: 0.5712\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2352 - accuracy: 0.5762 - val_loss: 0.2361 - val_accuracy: 0.5737\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2345 - accuracy: 0.5766 - val_loss: 0.2345 - val_accuracy: 0.5775\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2337 - accuracy: 0.5796 - val_loss: 0.2340 - val_accuracy: 0.5802\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2331 - accuracy: 0.5816 - val_loss: 0.2330 - val_accuracy: 0.5822\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2325 - accuracy: 0.5829 - val_loss: 0.2323 - val_accuracy: 0.5829\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2317 - accuracy: 0.5847 - val_loss: 0.2324 - val_accuracy: 0.5835\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.2310 - accuracy: 0.5868 - val_loss: 0.2312 - val_accuracy: 0.5865\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 24s 31ms/step - loss: 0.2304 - accuracy: 0.5876 - val_loss: 0.2305 - val_accuracy: 0.5873\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 25s 32ms/step - loss: 0.2299 - accuracy: 0.5899 - val_loss: 0.2300 - val_accuracy: 0.5895\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2293 - accuracy: 0.5911 - val_loss: 0.2300 - val_accuracy: 0.5914\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2286 - accuracy: 0.5935 - val_loss: 0.2302 - val_accuracy: 0.5905\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2280 - accuracy: 0.5946 - val_loss: 0.2294 - val_accuracy: 0.5918\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.2277 - accuracy: 0.5952 - val_loss: 0.2292 - val_accuracy: 0.5931\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2269 - accuracy: 0.5989 - val_loss: 0.2290 - val_accuracy: 0.5953\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2263 - accuracy: 0.6010 - val_loss: 0.2283 - val_accuracy: 0.5933\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 24s 29ms/step - loss: 0.2259 - accuracy: 0.6012 - val_loss: 0.2278 - val_accuracy: 0.5956\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2254 - accuracy: 0.6028 - val_loss: 0.2278 - val_accuracy: 0.5976\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2249 - accuracy: 0.6058 - val_loss: 0.2277 - val_accuracy: 0.5952\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.2243 - accuracy: 0.6068 - val_loss: 0.2276 - val_accuracy: 0.5976\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2237 - accuracy: 0.6081 - val_loss: 0.2272 - val_accuracy: 0.5991\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2232 - accuracy: 0.6107 - val_loss: 0.2267 - val_accuracy: 0.6000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2227 - accuracy: 0.6118 - val_loss: 0.2274 - val_accuracy: 0.6014\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2223 - accuracy: 0.6139 - val_loss: 0.2263 - val_accuracy: 0.6027\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.2217 - accuracy: 0.6153 - val_loss: 0.2260 - val_accuracy: 0.6033\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.2214 - accuracy: 0.6159 - val_loss: 0.2260 - val_accuracy: 0.6050\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.2209 - accuracy: 0.6172 - val_loss: 0.2262 - val_accuracy: 0.6056\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2204 - accuracy: 0.6187 - val_loss: 0.2255 - val_accuracy: 0.6065\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.2200 - accuracy: 0.6204 - val_loss: 0.2253 - val_accuracy: 0.6075\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2193 - accuracy: 0.6224 - val_loss: 0.2247 - val_accuracy: 0.6079\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2190 - accuracy: 0.6231 - val_loss: 0.2254 - val_accuracy: 0.6067\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2186 - accuracy: 0.6248 - val_loss: 0.2243 - val_accuracy: 0.6098\n",
      "INFO:tensorflow:Assets written to: ../models/lstm-timerage-14/assets\n",
      "577/577 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.5214\n",
      "model evaluation:  [0.2552919387817383, 0.5213503837585449]\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "histories = []\n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=256\n",
    "\n",
    "for TIMERANGE in range(2, 15):\n",
    "    \n",
    "    X_train, X_test = [np.ndarray(shape=(0, TIMERANGE, NUM_FEATURES)) for i in range(2)]\n",
    "    Y_train, Y_test = [np.ndarray(shape=(0)) for i in range(2)]\n",
    "    for stock in all_stocks:\n",
    "        X = scaler.transform(stock)\n",
    "        X = pca.transform(X)\n",
    "        x_train, x_test = prepare_input_data(X, timerange=TIMERANGE)\n",
    "        y_train, y_test = prepare_output_data(stock['close'], timerange=TIMERANGE)\n",
    "        X_train = np.append(X_train, x_train, axis=0)\n",
    "        Y_train = np.append(Y_train, y_train, axis=0)\n",
    "        X_test = np.append(X_test, x_test, axis=0)\n",
    "        Y_test = np.append(Y_test, y_test, axis=0)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    history = model.fit(X_train, Y_train, validation_split=0.1, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    histories.append(history)\n",
    "    \n",
    "    model.save('../models/lstm-timerage-' + str(TIMERANGE))\n",
    "    \n",
    "    print('model evaluation: ', model.evaluate(X_test, Y_test))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
